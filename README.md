Certainly! Here’s a **professional, detailed GitHub `README.md`** for your Gradio + Ollama + Open-Meteo agromet advisory application.
It explains the purpose, setup, features, flow, and how to use the system.

---

# Evapotranspiration & Agro-Advisory System

*Powered by Raspberry Pi 4B, Local LLMs via Ollama, and Open-Meteo API*

---

## Overview

This project provides a **web-based agrometeorological advisory tool** that combines weather data from Open-Meteo, advanced evapotranspiration (ET) calculations, and localized, farmer-friendly advice generated by local large language models (LLMs) running on a Raspberry Pi (or any compatible Linux host) via [Ollama](https://ollama.com/).
**Gradio** powers the user interface, making it easy for rural extension agents, scientists, and growers to obtain actionable, context-aware advice for their fields.

---

## Features

* **Location Search & Selection:**
  Search by district/city/village name (global coverage via Open-Meteo Geocoding API).
* **Multi-Model LLM Integration:**
  Switch between multiple local LLMs (e.g., TinyLlama, Qwen, etc.) hosted via Ollama; models are managed in memory for optimal performance.
* **Custom Forecast Window:**
  Choose a forecast period from 3 to 7 days.
* **ET Model Comparison:**
  Calculates and visualizes ET using multiple scientific methods: FAO ET₀, Hargreaves-Samani, Turc, Priestley-Taylor, and Makkink.
* **Intuitive, Rural-Friendly Advisory:**
  Local LLM generates simple, pointwise farm advice with examples, covering:

  1. Irrigation plan
  2. Crop/soil action
  3. Livestock/labour management
  4. Pest & disease watch
  5. Input-saving tip
* **Data Logging:**
  All results are logged in a local SQLite database for traceability and research.
* **Interactive Outputs:**

  * ET metrics table
  * Comparative bar chart
  * Model information
  * Farmer advisory (LLM output)

---

## Requirements

* **Hardware:**

  * Raspberry Pi 4B (recommended) or compatible Linux system
  * Sufficient RAM for LLMs (ideally >4GB for sub-1B models)
* **Software:**

  * Python 3.8+
  * [Ollama](https://ollama.com/) (for local LLM serving)
  * Gradio
  * pandas, numpy, matplotlib, requests, sqlite3

**Install requirements:**

`requirements.txt`:

```
requests
pandas
gradio
matplotlib
numpy
```

```bash
pip install -r requirements.txt
```

```bash
# Ollama: follow [Ollama install docs](https://ollama.com/)
```

---

## Usage

1. **Start Ollama and Load LLMs**
   Make sure your desired LLMs are available in Ollama:

   ```bash
   ollama serve
   ollama pull qwen:0.5b   # Example: add other models as desired
   ```

2. **Run the Application**

   ```bash
   python agromet_advisory.py
   ```

   The Gradio UI will start at:
   [http://localhost:7860](http://localhost:7860)

3. **How to Use:**

   * **Select** the LLM model (from dropdown)
   * **Enter** your location name (city, village, district, etc.)
   * **Set** forecast days (3–7)
   * **Click** "Search Location" and select the desired location if multiple
   * **Click** "Generate ET Forecast & Local LLM Advisory"
   * **Review** the outputs: ET table, ET chart, model info, and actionable farm advice

---

## Customization

* **Add/Remove LLM Models:**
  Pull new models via Ollama and restart the app.
* **Change Advisory Prompt:**
  Edit the `ollama_advice()` function to tune few-shot examples or language for your region.
* **Database:**
  The app stores all runs in `agromet_et.sqlite`—analyze or export data as needed.

---

## Troubleshooting

* If you see errors about models not loading, ensure Ollama is running and models are pulled.
* For slow responses, use smaller LLMs (<1B parameters) on Raspberry Pi.
* Weather or location not found? Check for typos or try a nearby city/village.

---

## Acknowledgements

* [Open-Meteo API](https://open-meteo.com/) for global weather and geocoding
* [Ollama](https://ollama.com/) for local LLM inference
* [Gradio](https://gradio.app/) for rapid web UI prototyping

---

## License

Apache-2.0 License (see [LICENSE](LICENSE) for details)

---
